general:
    expt_name: qk_regtr_full_pointformer

accelerate:
    gradient_accumulation_steps: 2
    mixed_precision: null
    seed: 0
    enable_broadcast_buffers: True
    find_unused_parameters: False
    gradient_as_bucket_view: False

dataset:
    train_batch_size: 4
    val_batch_size: 4
    dataset: modelnet
    root: "/home/jerrydty/Uni-corr/Superpoints_Registration/data/modelnet40_ply_hdf5_2048"
    train_meta_data: "/home/jerrydty/Uni-corr/Superpoints_Registration/data/metadata/modelnet_train_files.txt"
    val_meta_data: "/home/jerrydty/Uni-corr/Superpoints_Registration/data/metadata/modelnet_test_files.txt"
    grid_size: 0.02
    max_points: 30000
    max_queries: 2000
    matching_radius_3d: 0.0375
    downsample_voxel_size: null
    use_augmentation: True
    normalize_points: True
    bidirectional: True

train_options:
    niter: -400  # 400 epochs

solver:
    optimizer: AdamW
    base_lr: 0.0001
    weight_decay: 0.0001
    grad_clip: 0.1
    scheduler: 'step'
    scheduler_param: [127800, 0.5]  # Decay by 0.5 every 100 epochs


# Use a shallower backbone to maintain resolution
pointformer_options:
    in_channels: 3
    stride: [ 2, 2, 2, 2 ]
    enc_depths: [ 2, 2, 2, 6, 2 ]
    enc_channels: [ 48, 96, 192, 384, 768 ]
    enc_num_head: [ 2, 4, 8, 16, 32 ]
    enc_patch_size: [ 1024, 1024, 1024, 1024, 1024 ]
    project_dim: 1024
    mlp_ratio: 4
    point_order: ["z", "z-trans", "hilbert", "hilbert-trans"]
    qkv_bias: True
    qk_scale: None
    attn_drop: 0.0
    proj_drop: 0.0
    drop_path: 0.3
    pre_norm: True
    shuffle_orders: True
    enable_rpe: False
    enable_flash: False
decoder_options:
    depth: 12
    num_heads: 16
    enc_embed_dim: 1024
    enc_embed_dim_3d: 768
    dec_embed_dim: 768              # additional dims to account for point cloud
    pred_dim_3d: 4                  # [(x,y,z), confidence]
    point_patch_size: 1024
    mlp_ratio: 4
    qkv_bias: True
    norm_mem: True
    rope: null
    attn_drop: 0.0
    proj_drop: 0.0
    drop_path: 0.3
    query_pos_embed_3d: "coords_sine"
    use_flash_attn: False

lgr:
    use_lgr: False
    num_refinement_steps: 5
    acceptance_radius: 0.05

ransac:
    use_ransac: False

model:
    model: qk_regtr_full_pointformer.RegTR

    remove_points_from_val: False

    # Threshold Correlation values
    threshold_corr: False
    corr_threshold: 0.5

    # Use Overlap values to remove outliers
    remove_outliers_overlap: False
    overlap_threshold: 0.5
    use_overlap_as_weights: False

    # Lowe's ratio test
    use_ratio_test: False
    lowe_thres: 0.9

    # Sinkhorn
    use_sinkhorn: False
    sinkhorn_itr: 1
    slack: False
    use_attn_affinity: False
    use_corr_affinity: False

    # Transformer
    attention_type: dot_prod
    nhead: 8
    d_embed: 768
    d_feedforward: 1024
    dropout: 0.0  # dropout not compatible
    pre_norm: True
    transformer_act: relu

    # Transformer encoder
    num_encoder_layers: 6
    transformer_encoder_has_pos_emb: True
    sa_val_has_pos_emb: True
    ca_val_has_pos_emb: True
    pos_emb_type: sine  # either 'sine' or 'learned'

    # Correspondence decoding
    corr_decoder_has_pos_emb: True
    direct_regress_coor: True  # Whether to regress coordinates using MLP (True) or a final attention layer (False)


losses:
    feature_loss: False
    reg_loss: l1
    mode: exp
    alpha: 0.2
    vmax: inf
    vmin: 1

validation:
    # Registration success criteria. We use this to pick the best checkpoint
    reg_success_thresh_rot: 10
    reg_success_thresh_trans: 0.1
